# **Medical Scan Patch Classification Pipeline**

This project is a comprehensive deep learning pipeline for analyzing CT scans. It handles the full workflow from raw NIfTI data to an interactive inference application. The pipeline segments CT volumes into organ-specific 2D patches, balances the dataset, trains classification models (Custom CNN & ResNet), and provides a web interface for analysis.

## **Project Structure**

### **1\. Data Processing**

* **main.py**: The entry point for the data extraction pipeline. It iterates through subject folders, processes NIfTI volumes, and extracts training patches.  
* **config.py**: Central configuration file defining paths, CT windowing settings, patch size (64x64), and thresholds.  
* **nifti\_utils.py**: Utilities for loading NIfTI files and combining TotalSegmentator masks.  
* **patch\_utils.py**: Logic for extracting valid patches based on purity and fill ratios.  
* **image\_utils.py**: Handles CT normalization (Hounsfield Unit windowing) and slicing 3D volumes into 2D images.  
* **normalizer.py**: Balances the raw dataset by undersampling over-represented classes and augmenting rare classes (rotation, mirroring, brightness).

### **2\. Training**

* **trainSingleGPU.py**: Trains a custom "Very Deep" CNN architecture from scratch. Includes TensorBoard logging and generates a confusion matrix.  
* **transferLearning.py**: Fine-tunes a pre-trained ResNet18 model using Transfer Learning. Implements early stopping and heavy data augmentation (RandAugment).

### **3\. Evaluation & Application**

* **measureInference.py**: Benchmarks the inference speed (FPS) of trained models on CPU/GPU.  
* **gradioApp.py**: An interactive web application where users can upload a CT slice, click on a region, and get a classification prediction for that specific 64x64 patch.

## **⚙Installation**

1. **Clone the repository:**  
   git clone \<repository-url\>  
   cd \<repository-directory\>

2. Install dependencies:  
   It is recommended to use a virtual environment.  
   pip install \-r requirements.txt

   *Note: Ensure you have the correct version of PyTorch installed for your CUDA version if you plan to train on GPU.*  
3. TotalSegmentator Setup:  
   This pipeline relies on totalsegmentator for anatomical mapping. Ensure it is properly installed and configured.

## **End-to-End Usage Workflow**

### **Step 0: Data Preparation (Crucial)**

For the pipeline to function, your raw data must be organized in a specific structure. The scripts expect a root input directory where each subdirectory represents a patient.

**Required Directory Structure:**

/path/to/raw\_subjects/       \<-- This is your INPUT\_DATA\_DIR  
├── Subject\_001/  
│   ├── ct.nii.gz            \<-- The raw CT scan (NIfTI format)  
│   └── segmentations/       \<-- Folder containing binary masks per organ  
│       ├── liver.nii.gz  
│       ├── kidney\_right.nii.gz  
│       ├── spleen.nii.gz  
│       └── ... (other masks generated by TotalSegmentator)  
├── Subject\_002/  
│   ├── ct.nii.gz  
│   └── segmentations/  
│       └── ...  
└── ...

* **ct.nii.gz**: Must be named exactly this.  
* **segmentations/**: This folder is required if combined.nii.gz does not already exist. The script main.py will look here to generate a single multi-label mask using totalsegmentator.

### **Step 1: Configure Paths**

Open config.py and set the following paths to match your environment:

* INPUT\_DATA\_DIR: Path to the folder structure described in Step 0\.  
* OUTPUT\_PATCH\_DIR: Where you want the raw extracted patches to be saved.  
* NORMALIZED\_DATA\_DIR: Where the final balanced dataset will live.

### **Step 2: Extract Patches**

Run the extraction pipeline. This script performs the following logic per subject:

1. **Combine Masks**: Merges individual files in segmentations/ into combined.nii.gz.  
2. **Load & Window**: Loads the CT, applies Hounsfield Unit windowing (Soft Tissue: WL 40, WW 400), and normalizes to 0-255.  
3. **Slice**: Cuts the 3D volume into 2D PNG slices.  
4. **Patch**: Slides a 64x64 window over the slices. If a patch contains \>95% of a specific organ (purity threshold), it is saved.

python main.py

### **Step 3: Normalize Dataset**

The raw extraction often results in class imbalance (e.g., thousands of Liver patches but few Adrenal Gland patches). The normalizer.py script balances this:

1. Open normalizer.py and update SOURCE\_DIR (to your OUTPUT\_PATCH\_DIR) and DEST\_DIR (to your NORMALIZED\_DATA\_DIR).  
2. Set TARGET\_COUNT (e.g., 500 images per class).

The script will:

* **Undersample**: Randomly pick 500 images if a class has too many.  
* **Augment**: Apply rotation, mirroring, and brightness changes to generate new images if a class has too few.

python normalizer.py

### **Step 4: Train Models**

You have two training options. Update DATA\_DIR in the respective script to point to your NORMALIZED\_DATA\_DIR.

Option A: Train Custom CNN (Scratch)  
Good for understanding basic feature extraction.  
python trainSingleGPU.py

Option B: Train ResNet (Transfer Learning)  
Recommended for higher accuracy. Uses a pre-trained ResNet18 backbone.  
python transferLearning.py

*Outputs:*

* Check runs/ for TensorBoard logs (loss/accuracy curves).  
* Confusion matrices and model checkpoints (.pth) are saved in the root directory.

### **Step 5: Interactive Inference**

Launch the web interface to visualize model performance.

python gradioApp.py

* This starts a local server at http://127.0.0.1:7860.  
* **Usage**: Upload a CT slice image (PNG/JPG), select a model, and click on an organ to classify that specific 64x64 region.  
* **Auto-Detect Classes**: Use the "Advanced" tab in the UI to scan your dataset folder and automatically update the class labels.

### **Step 6: Benchmark (Optional)**

Measure the inference speed (Frames Per Second) of your saved models.

python measureInference.py

## **Outputs**

* **Patches**: Saved in class-specific folders (e.g., liver, kidney, pancreas).  
* **Models**: Saved as .pth files (e.g., model\_single\_gpu2.pth, best\_model\_frozen.pth).  
* **Metrics**: Speed metrics saved to CSVs; Confusion matrices saved as PNGs.